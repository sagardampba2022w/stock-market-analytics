{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "86240dcd",
   "metadata": {},
   "source": [
    "---\n",
    "### Question 1: [Index] S&P 500 Stocks Added to the Index\n",
    "\n",
    "**Which year had the highest number of additions?**\n",
    "\n",
    "Using the list of S&P 500 companies from Wikipedia's [S&P 500 companies page](https://en.wikipedia.org/wiki/List_of_S%26P_500_companies), download the data including the year each company was added to the index.\n",
    "* Create a DataFrame with company tickers, names, and the year they were added.\n",
    "* Extract the year from the addition date and calculate the number of stocks added each year.\n",
    "* Which year had the highest number of additions (1957 doesn't count, as it was the year when the S&P 500 index was founded)? Write down this year as your answer (the most recent one, if you have several records).\n",
    "\n",
    "*Context*: \n",
    "> \"Following the announcement, all four new entrants saw their stock prices rise in extended trading on Friday\" - recent examples of S&P 500 additions include DASH, WSM, EXE, TKO in 2025 ([Nasdaq article](https://www.nasdaq.com/articles/sp-500-reshuffle-dash-tko-expe-wsm-join-worth-buying)).\n",
    "\n",
    "*Additional*: How many current S&P 500 stocks have been in the index for more than 20 years? When stocks are added to the S&P 500, they usually experience a price bump as investors and index funds buy shares following the announcement.\n",
    "\n",
    "# ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bdbb07db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "#Fin Data Sources\n",
    "import yfinance as yf\n",
    "import pandas_datareader as pdr\n",
    "\n",
    "#Data viz\n",
    "import plotly.graph_objs as go\n",
    "import plotly.express as px\n",
    "\n",
    "import time\n",
    "from datetime import date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "44476338",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year with the most additions to S&P 500 (excluding 1957): 2017\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "url = 'https://en.wikipedia.org/wiki/List_of_S%26P_500_companies'\n",
    "tables = pd.read_html(url)\n",
    "df = tables[0].copy()\n",
    "\n",
    "\n",
    "final_df= df[['Symbol','Security','Founded','Date added']].copy()\n",
    "\n",
    "# Convert 'Date added' to datetime, ignoring errors\n",
    "\n",
    "final_df['Date added'] = pd.to_datetime(final_df['Date added'], errors='coerce')\n",
    "\n",
    "# Drop NaT (missing values in Date added)\n",
    "final_df = final_df.dropna(subset=['Date added'])\n",
    "\n",
    "# Extract year from 'Date added'\n",
    "final_df['Year added'] = final_df['Date added'].dt.year\n",
    "\n",
    "# Count number of additions per year\n",
    "additions_per_year = final_df['Year added'].value_counts().sort_index()\n",
    "\n",
    "# Exclude 1957\n",
    "additions_filtered = additions_per_year[additions_per_year.index != 1957]\n",
    "\n",
    "# Find the year with the highest number of additions (most recent if tie)\n",
    "max_additions = additions_filtered.max()\n",
    "most_recent_max_year = additions_filtered[additions_filtered == max_additions].index.max()\n",
    "\n",
    "print(f\"Year with the most additions to S&P 500 (excluding 1957): {most_recent_max_year}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "466c71bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stocks in S&P 500 for more than 20 years: 427\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "current_year = datetime.now().year\n",
    "current_year\n",
    "\n",
    "final_df['Founded'] = pd.to_numeric(final_df['Founded'], errors='coerce')\n",
    "\n",
    "final_df['Years_in_Index'] = current_year - final_df['Founded']\n",
    "\n",
    "over_20_years = final_df[final_df['Years_in_Index'] > 20]\n",
    "print(f\"Stocks in S&P 500 for more than 20 years: {len(over_20_years)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b3b1d81",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3fcb5867",
   "metadata": {},
   "source": [
    "### Question 2. [Macro] Indexes YTD (as of 1 May 2025)\n",
    "\n",
    "**How many indexes (out of 10) have better year-to-date returns than the US (S&P 500) as of May 1, 2025?**\n",
    "\n",
    "Using Yahoo Finance World Indices data, compare the year-to-date (YTD) performance (1 January-1 May 2025) of major stock market indexes for the following countries:\n",
    "* United States - S&P 500 (^GSPC)\n",
    "* China - Shanghai Composite (000001.SS)\n",
    "* Hong Kong - HANG SENG INDEX (^HSI)\t\n",
    "* Australia - S&P/ASX 200 (^AXJO)\n",
    "* India - Nifty 50 (^NSEI)\n",
    "* Canada - S&P/TSX Composite (^GSPTSE)\n",
    "* Germany - DAX (^GDAXI)\n",
    "* United Kingdom - FTSE 100 (^FTSE)\n",
    "* Japan - Nikkei 225 (^N225)\n",
    "* Mexico - IPC Mexico (^MXX)\n",
    "* Brazil - Ibovespa (^BVSP)\n",
    "\n",
    "*Hint*: use start_date='2025-01-01' and end_date='2025-05-01' when downloading daily data in yfinance\n",
    "\n",
    "Context: \n",
    "> [Global Valuations: Who's Cheap, Who's Not?](https://simplywall.st/article/beyond-the-us-global-markets-after-yet-another-tariff-update) article suggests \"Other regions may be growing faster than the US and you need to diversify.\"\n",
    "\n",
    "Reference: Yahoo Finance World Indices - https://finance.yahoo.com/world-indices/\n",
    "\n",
    "*Additional*: How many of these indexes have better returns than the S&P 500 over 3, 5, and 10 year periods? Do you see the same trend?\n",
    "Note: For simplicity, ignore currency conversion effects.)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bb2f0618",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Period for indexes: 2025-01-01 to 2025-05-01\n"
     ]
    }
   ],
   "source": [
    "# end = date.today()\n",
    "# print(f'Year = {end.year}; month= {end.month}; day={end.day}')\n",
    "\n",
    "# start = date(year=end.year-10, month=end.month, day=end.day)\n",
    "# print(f'Period for indexes: {start} to {end} ')\n",
    "\n",
    "start = date(year=2025, month=1, day=1)\n",
    "\n",
    "end = date(year=2025, month=5, day=1)\n",
    "print(f'Period for indexes: {start} to {end}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "354b4def",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(81, 7)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ticker_obj = yf.Ticker(\"^GSPC\")\n",
    "\n",
    "sandp500_daily = ticker_obj.history(start = start,end =end,interval = \"1d\")\n",
    "sandp500_daily.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "92b225b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "\n",
    "class GetTickerData:\n",
    "    def __init__(self, tickers):\n",
    "        # Accept either a string (single ticker) or a list of tickers\n",
    "        if isinstance(tickers, str):\n",
    "            self.tickers = [tickers]\n",
    "        else:\n",
    "            self.tickers = tickers\n",
    "        self.data = {}\n",
    "\n",
    "    def get_data(self, start, end, combine=False):\n",
    "        \"\"\"\n",
    "        Download historical data for all tickers between start and end dates.\n",
    "\n",
    "        Parameters:\n",
    "        - start (str): Start date (e.g., '2023-01-01')\n",
    "        - end (str): End date (e.g., '2023-12-31')\n",
    "        - combine (bool): Whether to return a single combined DataFrame\n",
    "\n",
    "        Returns:\n",
    "        - dict: {ticker: DataFrame} if combine=False\n",
    "        - DataFrame: multi-index DataFrame if combine=True\n",
    "        \"\"\"\n",
    "        for ticker in self.tickers:\n",
    "            data = yf.Ticker(ticker).history(start=start, end=end, interval=\"1d\")\n",
    "            self.data[ticker] = data\n",
    "\n",
    "        if combine:\n",
    "            combined_df = pd.concat(self.data.values(), keys=self.data.keys(), names=[\"Ticker\", \"Date\"])\n",
    "            combined_df = combined_df.reset_index()\n",
    "            return combined_df\n",
    "        return self.data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5e2f977b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ticker</th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Dividends</th>\n",
       "      <th>Stock Splits</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>^GSPC</td>\n",
       "      <td>2025-01-02 00:00:00-05:00</td>\n",
       "      <td>5903.259766</td>\n",
       "      <td>5935.089844</td>\n",
       "      <td>5829.529785</td>\n",
       "      <td>5868.549805</td>\n",
       "      <td>3621680000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>^GSPC</td>\n",
       "      <td>2025-01-03 00:00:00-05:00</td>\n",
       "      <td>5891.069824</td>\n",
       "      <td>5949.339844</td>\n",
       "      <td>5888.660156</td>\n",
       "      <td>5942.470215</td>\n",
       "      <td>3667340000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>^GSPC</td>\n",
       "      <td>2025-01-06 00:00:00-05:00</td>\n",
       "      <td>5982.810059</td>\n",
       "      <td>6021.040039</td>\n",
       "      <td>5960.009766</td>\n",
       "      <td>5975.379883</td>\n",
       "      <td>4940120000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>^GSPC</td>\n",
       "      <td>2025-01-07 00:00:00-05:00</td>\n",
       "      <td>5993.259766</td>\n",
       "      <td>6000.680176</td>\n",
       "      <td>5890.680176</td>\n",
       "      <td>5909.029785</td>\n",
       "      <td>4517330000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>^GSPC</td>\n",
       "      <td>2025-01-08 00:00:00-05:00</td>\n",
       "      <td>5910.660156</td>\n",
       "      <td>5927.890137</td>\n",
       "      <td>5874.779785</td>\n",
       "      <td>5918.250000</td>\n",
       "      <td>4441740000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Ticker                       Date         Open         High          Low  \\\n",
       "0  ^GSPC  2025-01-02 00:00:00-05:00  5903.259766  5935.089844  5829.529785   \n",
       "1  ^GSPC  2025-01-03 00:00:00-05:00  5891.069824  5949.339844  5888.660156   \n",
       "2  ^GSPC  2025-01-06 00:00:00-05:00  5982.810059  6021.040039  5960.009766   \n",
       "3  ^GSPC  2025-01-07 00:00:00-05:00  5993.259766  6000.680176  5890.680176   \n",
       "4  ^GSPC  2025-01-08 00:00:00-05:00  5910.660156  5927.890137  5874.779785   \n",
       "\n",
       "         Close      Volume  Dividends  Stock Splits  \n",
       "0  5868.549805  3621680000        0.0           0.0  \n",
       "1  5942.470215  3667340000        0.0           0.0  \n",
       "2  5975.379883  4940120000        0.0           0.0  \n",
       "3  5909.029785  4517330000        0.0           0.0  \n",
       "4  5918.250000  4441740000        0.0           0.0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tickers = [\"^GSPC\",\"000001.SS\",\"^HSI\",\"^AXJO\",\"^NSEI\",\"^GSPTSE\",\"^GDAXI\",\"^FTSE\",\"^N225\",\"^MXX\",\"^BVSP\"]\n",
    "data_fetcher = GetTickerData(tickers)\n",
    "all_data = data_fetcher.get_data(start=start, end=end, combine=True)\n",
    "\n",
    "all_data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d7413e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_growth_metrics(df):\n",
    "    \"\"\"\n",
    "    Adds Day-over-Day (DoD), Quarter-over-Quarter (QoQ), Year-over-Year (YoY), and Year-to-Date (YTD) growth\n",
    "    using the 'Date' column for year reference.\n",
    "    \n",
    "    Assumes 'Date' column exists and is datetime type.\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "\n",
    "    # Ensure 'Date' column is datetime\n",
    "    df['Date'] = pd.to_datetime(df['Date'], utc=True)\n",
    "\n",
    "    # Sort by Date in case it's not sorted\n",
    "    df = df.sort_values('Date')\n",
    "\n",
    "    # Day-over-Day % change\n",
    "    df['DoD_Growth'] = df['Close'].pct_change()\n",
    "\n",
    "    # QoQ and YoY growth by trading days\n",
    "    df['QoQ_Growth'] = df['Close'].pct_change(periods=63)\n",
    "    df['YoY_Growth'] = df['Close'].pct_change(periods=252)\n",
    "\n",
    "    # YTD growth based on first trading day of the year\n",
    "    df['Year'] = df['Date'].dt.year\n",
    "    df['YTD_Base'] = df.groupby('Year')['Close'].transform('first')\n",
    "    df['YTD_Growth'] = (df['Close'] / df['YTD_Base']) - 1\n",
    "\n",
    "    # Clean up\n",
    "    df.drop(columns=['YTD_Base'], inplace=True)\n",
    "\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b6de0c2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ticker</th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Dividends</th>\n",
       "      <th>Stock Splits</th>\n",
       "      <th>DoD_Growth</th>\n",
       "      <th>QoQ_Growth</th>\n",
       "      <th>YoY_Growth</th>\n",
       "      <th>Year</th>\n",
       "      <th>YTD_Growth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>^NSEI</td>\n",
       "      <td>2024-12-31 18:30:00+00:00</td>\n",
       "      <td>23637.650391</td>\n",
       "      <td>23822.800781</td>\n",
       "      <td>23562.800781</td>\n",
       "      <td>23742.900391</td>\n",
       "      <td>154900</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>^AXJO</td>\n",
       "      <td>2025-01-01 13:00:00+00:00</td>\n",
       "      <td>8159.100098</td>\n",
       "      <td>8204.200195</td>\n",
       "      <td>8146.600098</td>\n",
       "      <td>8201.200195</td>\n",
       "      <td>304400</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.654583</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2025</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>^HSI</td>\n",
       "      <td>2025-01-01 16:00:00+00:00</td>\n",
       "      <td>19932.800781</td>\n",
       "      <td>19932.800781</td>\n",
       "      <td>19542.980469</td>\n",
       "      <td>19623.320312</td>\n",
       "      <td>4033400000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.392738</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2025</td>\n",
       "      <td>1.392738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000001.SS</td>\n",
       "      <td>2025-01-01 16:00:00+00:00</td>\n",
       "      <td>3347.938965</td>\n",
       "      <td>3351.721924</td>\n",
       "      <td>3242.086914</td>\n",
       "      <td>3262.561035</td>\n",
       "      <td>561400</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.833741</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2025</td>\n",
       "      <td>-0.602185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>^NSEI</td>\n",
       "      <td>2025-01-01 18:30:00+00:00</td>\n",
       "      <td>23783.000000</td>\n",
       "      <td>24226.699219</td>\n",
       "      <td>23751.550781</td>\n",
       "      <td>24188.650391</td>\n",
       "      <td>283200</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.414007</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2025</td>\n",
       "      <td>1.949404</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Ticker                      Date          Open          High  \\\n",
       "0      ^NSEI 2024-12-31 18:30:00+00:00  23637.650391  23822.800781   \n",
       "1      ^AXJO 2025-01-01 13:00:00+00:00   8159.100098   8204.200195   \n",
       "2       ^HSI 2025-01-01 16:00:00+00:00  19932.800781  19932.800781   \n",
       "3  000001.SS 2025-01-01 16:00:00+00:00   3347.938965   3351.721924   \n",
       "4      ^NSEI 2025-01-01 18:30:00+00:00  23783.000000  24226.699219   \n",
       "\n",
       "            Low         Close      Volume  Dividends  Stock Splits  \\\n",
       "0  23562.800781  23742.900391      154900        0.0           0.0   \n",
       "1   8146.600098   8201.200195      304400        0.0           0.0   \n",
       "2  19542.980469  19623.320312  4033400000        0.0           0.0   \n",
       "3   3242.086914   3262.561035      561400        0.0           0.0   \n",
       "4  23751.550781  24188.650391      283200        0.0           0.0   \n",
       "\n",
       "   DoD_Growth  QoQ_Growth  YoY_Growth  Year  YTD_Growth  \n",
       "0         NaN         NaN         NaN  2024    0.000000  \n",
       "1   -0.654583         NaN         NaN  2025    0.000000  \n",
       "2    1.392738         NaN         NaN  2025    1.392738  \n",
       "3   -0.833741         NaN         NaN  2025   -0.602185  \n",
       "4    6.414007         NaN         NaN  2025    1.949404  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df_growth = add_growth_metrics(all_data)\n",
    "final_df_growth.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fc63a9b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ticker</th>\n",
       "      <th>Date</th>\n",
       "      <th>YTD_Growth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>884</th>\n",
       "      <td>^BVSP</td>\n",
       "      <td>2025-04-30 03:00:00+00:00</td>\n",
       "      <td>15.469175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>^MXX</td>\n",
       "      <td>2025-04-30 06:00:00+00:00</td>\n",
       "      <td>5.859884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>878</th>\n",
       "      <td>^N225</td>\n",
       "      <td>2025-04-29 15:00:00+00:00</td>\n",
       "      <td>3.395135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>^GSPTSE</td>\n",
       "      <td>2025-04-30 04:00:00+00:00</td>\n",
       "      <td>2.029032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>881</th>\n",
       "      <td>^NSEI</td>\n",
       "      <td>2025-04-29 18:30:00+00:00</td>\n",
       "      <td>1.967151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>882</th>\n",
       "      <td>^GDAXI</td>\n",
       "      <td>2025-04-29 22:00:00+00:00</td>\n",
       "      <td>1.743133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>880</th>\n",
       "      <td>^HSI</td>\n",
       "      <td>2025-04-29 16:00:00+00:00</td>\n",
       "      <td>1.697094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>883</th>\n",
       "      <td>^FTSE</td>\n",
       "      <td>2025-04-29 23:00:00+00:00</td>\n",
       "      <td>0.035812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>877</th>\n",
       "      <td>^AXJO</td>\n",
       "      <td>2025-04-29 14:00:00+00:00</td>\n",
       "      <td>-0.009145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>885</th>\n",
       "      <td>^GSPC</td>\n",
       "      <td>2025-04-30 04:00:00+00:00</td>\n",
       "      <td>-0.320946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>879</th>\n",
       "      <td>000001.SS</td>\n",
       "      <td>2025-04-29 16:00:00+00:00</td>\n",
       "      <td>-0.600177</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Ticker                      Date  YTD_Growth\n",
       "884      ^BVSP 2025-04-30 03:00:00+00:00   15.469175\n",
       "887       ^MXX 2025-04-30 06:00:00+00:00    5.859884\n",
       "878      ^N225 2025-04-29 15:00:00+00:00    3.395135\n",
       "886    ^GSPTSE 2025-04-30 04:00:00+00:00    2.029032\n",
       "881      ^NSEI 2025-04-29 18:30:00+00:00    1.967151\n",
       "882     ^GDAXI 2025-04-29 22:00:00+00:00    1.743133\n",
       "880       ^HSI 2025-04-29 16:00:00+00:00    1.697094\n",
       "883      ^FTSE 2025-04-29 23:00:00+00:00    0.035812\n",
       "877      ^AXJO 2025-04-29 14:00:00+00:00   -0.009145\n",
       "885      ^GSPC 2025-04-30 04:00:00+00:00   -0.320946\n",
       "879  000001.SS 2025-04-29 16:00:00+00:00   -0.600177"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latest_ytd = (\n",
    "    final_df_growth.sort_values('Date')                # ensure dates are sorted\n",
    "    .groupby('Ticker', as_index=False)                 # group by Ticker\n",
    "    .tail(1)                                            # get the latest row per Ticker\n",
    "    .sort_values('YTD_Growth', ascending=False)        # sort by YTD growth\n",
    ")\n",
    "\n",
    "latest_ytd[['Ticker', 'Date', 'YTD_Growth']]  # show top 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "252bae45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ticker\n",
       "000001.SS    78\n",
       "^AXJO        81\n",
       "^BVSP        81\n",
       "^FTSE        83\n",
       "^GDAXI       83\n",
       "^GSPC        81\n",
       "^GSPTSE      83\n",
       "^HSI         79\n",
       "^MXX         81\n",
       "^N225        78\n",
       "^NSEI        80\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df_growth.groupby('Ticker').size()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5362d8f3",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Choose a ticker (example: 'AAPL')\n",
    "ticker = '^HSI'  # Replace with the desired ticker\n",
    "\n",
    "# Filter the data for that ticker\n",
    "df_ticker = final_df_growth[final_df_growth['Ticker'] == ticker].copy()\n",
    "\n",
    "# Ensure 'Date' is datetime and set as index for time series plotting\n",
    "df_ticker['Date'] = pd.to_datetime(df_ticker['Date'])\n",
    "df_ticker = df_ticker.sort_values('Date').set_index('Date')\n",
    "\n",
    "# Simple line plot using pandas\n",
    "df_ticker['DoD_Growth'].plot.line()\n",
    "\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('DoD Growth')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bec181df",
   "metadata": {},
   "source": [
    "### Question 3. [Index] S&P 500 Market Corrections Analysis\n",
    "\n",
    "\n",
    "**Calculate the median duration (in days) of significant market corrections in the S&P 500 index.**\n",
    "\n",
    "For this task, define a correction as an event when a stock index goes down by **more than 5%** from the closest all-time high maximum.\n",
    "\n",
    "Steps:\n",
    "1. Download S&P 500 historical data (1950-present) using yfinance\n",
    "2. Identify all-time high points (where price exceeds all previous prices)\n",
    "3. For each pair of consecutive all-time highs, find the minimum price in between\n",
    "4. Calculate drawdown percentages: (high - low) / high × 100\n",
    "5. Filter for corrections with at least 5% drawdown\n",
    "6. Calculate the duration in days for each correction period\n",
    "7. Determine the 25th, 50th (median), and 75th percentiles for correction durations\n",
    "\n",
    "*Context:* \n",
    "> * Investors often wonder about the typical length of market corrections when deciding \"when to buy the dip\" ([Reddit discussion](https://www.reddit.com/r/investing/comments/1jrqnte/when_are_you_buying_the_dip/?rdt=64135)).\n",
    "\n",
    "> * [A Wealth of Common Sense - How Often Should You Expect a Stock Market Correction?](https://awealthofcommonsense.com/2022/01/how-often-should-you-expect-a-stock-market-correction/)\n",
    "\n",
    "*Hint (use this data to compare with your results)*: Here is the list of top 10 largest corrections by drawdown:\n",
    "* 2007-10-09 to 2009-03-09: 56.8% drawdown over 517 days\n",
    "* 2000-03-24 to 2002-10-09: 49.1% drawdown over 929 days\n",
    "* 1973-01-11 to 1974-10-03: 48.2% drawdown over 630 days\n",
    "* 1968-11-29 to 1970-05-26: 36.1% drawdown over 543 days\n",
    "* 2020-02-19 to 2020-03-23: 33.9% drawdown over 33 days\n",
    "* 1987-08-25 to 1987-12-04: 33.5% drawdown over 101 days\n",
    "* 1961-12-12 to 1962-06-26: 28.0% drawdown over 196 days\n",
    "* 1980-11-28 to 1982-08-12: 27.1% drawdown over 622 days\n",
    "* 2022-01-03 to 2022-10-12: 25.4% drawdown over 282 days\n",
    "* 1966-02-09 to 1966-10-07: 22.2% drawdown over 240 days\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "61867f9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18952, 9)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ticker</th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Dividends</th>\n",
       "      <th>Stock Splits</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>^GSPC</td>\n",
       "      <td>1950-01-03 00:00:00-05:00</td>\n",
       "      <td>16.66</td>\n",
       "      <td>16.66</td>\n",
       "      <td>16.66</td>\n",
       "      <td>16.66</td>\n",
       "      <td>1260000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>^GSPC</td>\n",
       "      <td>1950-01-04 00:00:00-05:00</td>\n",
       "      <td>16.85</td>\n",
       "      <td>16.85</td>\n",
       "      <td>16.85</td>\n",
       "      <td>16.85</td>\n",
       "      <td>1890000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>^GSPC</td>\n",
       "      <td>1950-01-05 00:00:00-05:00</td>\n",
       "      <td>16.93</td>\n",
       "      <td>16.93</td>\n",
       "      <td>16.93</td>\n",
       "      <td>16.93</td>\n",
       "      <td>2550000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>^GSPC</td>\n",
       "      <td>1950-01-06 00:00:00-05:00</td>\n",
       "      <td>16.98</td>\n",
       "      <td>16.98</td>\n",
       "      <td>16.98</td>\n",
       "      <td>16.98</td>\n",
       "      <td>2010000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>^GSPC</td>\n",
       "      <td>1950-01-09 00:00:00-05:00</td>\n",
       "      <td>17.08</td>\n",
       "      <td>17.08</td>\n",
       "      <td>17.08</td>\n",
       "      <td>17.08</td>\n",
       "      <td>2520000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Ticker                      Date   Open   High    Low  Close   Volume  \\\n",
       "0  ^GSPC 1950-01-03 00:00:00-05:00  16.66  16.66  16.66  16.66  1260000   \n",
       "1  ^GSPC 1950-01-04 00:00:00-05:00  16.85  16.85  16.85  16.85  1890000   \n",
       "2  ^GSPC 1950-01-05 00:00:00-05:00  16.93  16.93  16.93  16.93  2550000   \n",
       "3  ^GSPC 1950-01-06 00:00:00-05:00  16.98  16.98  16.98  16.98  2010000   \n",
       "4  ^GSPC 1950-01-09 00:00:00-05:00  17.08  17.08  17.08  17.08  2520000   \n",
       "\n",
       "   Dividends  Stock Splits  \n",
       "0        0.0           0.0  \n",
       "1        0.0           0.0  \n",
       "2        0.0           0.0  \n",
       "3        0.0           0.0  \n",
       "4        0.0           0.0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sandp_ticker = \"^GSPC\"\n",
    "\n",
    "start = date(year=1950, month=1, day=1)\n",
    "end = date(year=2025, month=5, day=1)\n",
    "\n",
    "data_fetcher = GetTickerData(sandp_ticker)\n",
    "sandpdata = data_fetcher.get_data(start=start, end=end, combine=True)\n",
    "\n",
    "print(sandpdata.shape)\n",
    "sandpdata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b0a217e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sandpdata['AllTimeHigh'] = sandpdata['Close'].cummax()\n",
    "all_time_highs = sandpdata[sandpdata['Close'] == sandpdata['AllTimeHigh']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "02db64e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ticker</th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Dividends</th>\n",
       "      <th>Stock Splits</th>\n",
       "      <th>AllTimeHigh</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18852</th>\n",
       "      <td>^GSPC</td>\n",
       "      <td>2024-12-04 00:00:00-05:00</td>\n",
       "      <td>6069.390137</td>\n",
       "      <td>6089.839844</td>\n",
       "      <td>6061.060059</td>\n",
       "      <td>6086.490234</td>\n",
       "      <td>4003390000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6086.490234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18854</th>\n",
       "      <td>^GSPC</td>\n",
       "      <td>2024-12-06 00:00:00-05:00</td>\n",
       "      <td>6081.379883</td>\n",
       "      <td>6099.970215</td>\n",
       "      <td>6079.979980</td>\n",
       "      <td>6090.270020</td>\n",
       "      <td>3924830000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6090.270020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18884</th>\n",
       "      <td>^GSPC</td>\n",
       "      <td>2025-01-23 00:00:00-05:00</td>\n",
       "      <td>6076.319824</td>\n",
       "      <td>6118.729980</td>\n",
       "      <td>6074.669922</td>\n",
       "      <td>6118.709961</td>\n",
       "      <td>4432250000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6118.709961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18901</th>\n",
       "      <td>^GSPC</td>\n",
       "      <td>2025-02-18 00:00:00-05:00</td>\n",
       "      <td>6121.600098</td>\n",
       "      <td>6129.629883</td>\n",
       "      <td>6099.509766</td>\n",
       "      <td>6129.580078</td>\n",
       "      <td>4684980000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6129.580078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18902</th>\n",
       "      <td>^GSPC</td>\n",
       "      <td>2025-02-19 00:00:00-05:00</td>\n",
       "      <td>6117.759766</td>\n",
       "      <td>6147.430176</td>\n",
       "      <td>6111.149902</td>\n",
       "      <td>6144.149902</td>\n",
       "      <td>4562330000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6144.149902</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Ticker                      Date         Open         High          Low  \\\n",
       "18852  ^GSPC 2024-12-04 00:00:00-05:00  6069.390137  6089.839844  6061.060059   \n",
       "18854  ^GSPC 2024-12-06 00:00:00-05:00  6081.379883  6099.970215  6079.979980   \n",
       "18884  ^GSPC 2025-01-23 00:00:00-05:00  6076.319824  6118.729980  6074.669922   \n",
       "18901  ^GSPC 2025-02-18 00:00:00-05:00  6121.600098  6129.629883  6099.509766   \n",
       "18902  ^GSPC 2025-02-19 00:00:00-05:00  6117.759766  6147.430176  6111.149902   \n",
       "\n",
       "             Close      Volume  Dividends  Stock Splits  AllTimeHigh  \n",
       "18852  6086.490234  4003390000        0.0           0.0  6086.490234  \n",
       "18854  6090.270020  3924830000        0.0           0.0  6090.270020  \n",
       "18884  6118.709961  4432250000        0.0           0.0  6118.709961  \n",
       "18901  6129.580078  4684980000        0.0           0.0  6129.580078  \n",
       "18902  6144.149902  4562330000        0.0           0.0  6144.149902  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_time_highs.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1b1b14cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "corrections = []\n",
    "\n",
    "for i in range(1, len(all_time_highs)):\n",
    "    start = all_time_highs.iloc[i-1]\n",
    "    end = all_time_highs.iloc[i]\n",
    "    \n",
    "    # Subset between the two ATHs (excluding the endpoints)\n",
    "    mask = (sandpdata['Date'] > start['Date']) & (sandpdata['Date'] < end['Date'])\n",
    "    if sandpdata[mask].empty:\n",
    "        continue\n",
    "    interim_low = sandpdata[mask]['Close'].min()\n",
    "    interim_low_date = sandpdata[mask].loc[sandpdata[mask]['Close'].idxmin(), 'Date']\n",
    "    \n",
    "    drawdown = (start['Close'] - interim_low) / start['Close'] * 100\n",
    "    reco_duration = (end['Date'] - interim_low_date).days\n",
    "    correction_duration = (interim_low_date - start['Date']).days \n",
    "    full_cycle_duration = (end['Date'] - start['Date']).days\n",
    "\n",
    "\n",
    "    \n",
    "    if drawdown >= 5:\n",
    "        corrections.append({\n",
    "            'StartDate': start['Date'],\n",
    "            'InterimLowDate': interim_low_date,\n",
    "            'EndDate': end['Date'],\n",
    "            'StartClose': start['Close'],\n",
    "            'LowClose': interim_low,\n",
    "            'EndClose': end['Close'],\n",
    "            'DrawdownPercent': drawdown,\n",
    "            'RecoveryDuration': reco_duration,\n",
    "            'DrawdownDuration': correction_duration,\n",
    "            'FullCycleDuration': full_cycle_duration\n",
    "        })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ba4fc32e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>StartDate</th>\n",
       "      <th>InterimLowDate</th>\n",
       "      <th>EndDate</th>\n",
       "      <th>StartClose</th>\n",
       "      <th>LowClose</th>\n",
       "      <th>EndClose</th>\n",
       "      <th>DrawdownPercent</th>\n",
       "      <th>RecoveryDuration</th>\n",
       "      <th>DrawdownDuration</th>\n",
       "      <th>FullCycleDuration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>2007-10-09 00:00:00-04:00</td>\n",
       "      <td>2009-03-09 00:00:00-04:00</td>\n",
       "      <td>2013-03-28 00:00:00-04:00</td>\n",
       "      <td>1565.150024</td>\n",
       "      <td>676.530029</td>\n",
       "      <td>1569.189941</td>\n",
       "      <td>56.775388</td>\n",
       "      <td>1480</td>\n",
       "      <td>517</td>\n",
       "      <td>1997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>2000-03-24 00:00:00-05:00</td>\n",
       "      <td>2002-10-09 00:00:00-04:00</td>\n",
       "      <td>2007-05-30 00:00:00-04:00</td>\n",
       "      <td>1527.459961</td>\n",
       "      <td>776.760010</td>\n",
       "      <td>1530.229980</td>\n",
       "      <td>49.146948</td>\n",
       "      <td>1694</td>\n",
       "      <td>928</td>\n",
       "      <td>2622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1973-01-11 00:00:00-05:00</td>\n",
       "      <td>1974-10-03 00:00:00-04:00</td>\n",
       "      <td>1980-07-17 00:00:00-04:00</td>\n",
       "      <td>120.239998</td>\n",
       "      <td>62.279999</td>\n",
       "      <td>121.440002</td>\n",
       "      <td>48.203593</td>\n",
       "      <td>2114</td>\n",
       "      <td>629</td>\n",
       "      <td>2743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1968-11-29 00:00:00-05:00</td>\n",
       "      <td>1970-05-26 00:00:00-04:00</td>\n",
       "      <td>1972-03-06 00:00:00-05:00</td>\n",
       "      <td>108.370003</td>\n",
       "      <td>69.290001</td>\n",
       "      <td>108.769997</td>\n",
       "      <td>36.061641</td>\n",
       "      <td>650</td>\n",
       "      <td>542</td>\n",
       "      <td>1193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>2020-02-19 00:00:00-05:00</td>\n",
       "      <td>2020-03-23 00:00:00-04:00</td>\n",
       "      <td>2020-08-18 00:00:00-04:00</td>\n",
       "      <td>3386.149902</td>\n",
       "      <td>2237.399902</td>\n",
       "      <td>3389.780029</td>\n",
       "      <td>33.924960</td>\n",
       "      <td>148</td>\n",
       "      <td>32</td>\n",
       "      <td>180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>1987-08-25 00:00:00-04:00</td>\n",
       "      <td>1987-12-04 00:00:00-05:00</td>\n",
       "      <td>1989-07-26 00:00:00-04:00</td>\n",
       "      <td>336.769989</td>\n",
       "      <td>223.919998</td>\n",
       "      <td>338.049988</td>\n",
       "      <td>33.509515</td>\n",
       "      <td>599</td>\n",
       "      <td>101</td>\n",
       "      <td>701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1961-12-12 00:00:00-05:00</td>\n",
       "      <td>1962-06-26 00:00:00-04:00</td>\n",
       "      <td>1963-09-03 00:00:00-04:00</td>\n",
       "      <td>72.639999</td>\n",
       "      <td>52.320000</td>\n",
       "      <td>72.660004</td>\n",
       "      <td>27.973568</td>\n",
       "      <td>434</td>\n",
       "      <td>195</td>\n",
       "      <td>629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1980-11-28 00:00:00-05:00</td>\n",
       "      <td>1982-08-12 00:00:00-04:00</td>\n",
       "      <td>1982-11-03 00:00:00-05:00</td>\n",
       "      <td>140.520004</td>\n",
       "      <td>102.419998</td>\n",
       "      <td>142.869995</td>\n",
       "      <td>27.113582</td>\n",
       "      <td>83</td>\n",
       "      <td>621</td>\n",
       "      <td>705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>2022-01-03 00:00:00-05:00</td>\n",
       "      <td>2022-10-12 00:00:00-04:00</td>\n",
       "      <td>2024-01-19 00:00:00-05:00</td>\n",
       "      <td>4796.560059</td>\n",
       "      <td>3577.030029</td>\n",
       "      <td>4839.810059</td>\n",
       "      <td>25.425097</td>\n",
       "      <td>464</td>\n",
       "      <td>281</td>\n",
       "      <td>746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1966-02-09 00:00:00-05:00</td>\n",
       "      <td>1966-10-07 00:00:00-04:00</td>\n",
       "      <td>1967-05-04 00:00:00-04:00</td>\n",
       "      <td>94.059998</td>\n",
       "      <td>73.199997</td>\n",
       "      <td>94.320000</td>\n",
       "      <td>22.177335</td>\n",
       "      <td>209</td>\n",
       "      <td>239</td>\n",
       "      <td>448</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   StartDate            InterimLowDate  \\\n",
       "56 2007-10-09 00:00:00-04:00 2009-03-09 00:00:00-04:00   \n",
       "54 2000-03-24 00:00:00-05:00 2002-10-09 00:00:00-04:00   \n",
       "24 1973-01-11 00:00:00-05:00 1974-10-03 00:00:00-04:00   \n",
       "22 1968-11-29 00:00:00-05:00 1970-05-26 00:00:00-04:00   \n",
       "65 2020-02-19 00:00:00-05:00 2020-03-23 00:00:00-04:00   \n",
       "35 1987-08-25 00:00:00-04:00 1987-12-04 00:00:00-05:00   \n",
       "15 1961-12-12 00:00:00-05:00 1962-06-26 00:00:00-04:00   \n",
       "27 1980-11-28 00:00:00-05:00 1982-08-12 00:00:00-04:00   \n",
       "68 2022-01-03 00:00:00-05:00 2022-10-12 00:00:00-04:00   \n",
       "18 1966-02-09 00:00:00-05:00 1966-10-07 00:00:00-04:00   \n",
       "\n",
       "                     EndDate   StartClose     LowClose     EndClose  \\\n",
       "56 2013-03-28 00:00:00-04:00  1565.150024   676.530029  1569.189941   \n",
       "54 2007-05-30 00:00:00-04:00  1527.459961   776.760010  1530.229980   \n",
       "24 1980-07-17 00:00:00-04:00   120.239998    62.279999   121.440002   \n",
       "22 1972-03-06 00:00:00-05:00   108.370003    69.290001   108.769997   \n",
       "65 2020-08-18 00:00:00-04:00  3386.149902  2237.399902  3389.780029   \n",
       "35 1989-07-26 00:00:00-04:00   336.769989   223.919998   338.049988   \n",
       "15 1963-09-03 00:00:00-04:00    72.639999    52.320000    72.660004   \n",
       "27 1982-11-03 00:00:00-05:00   140.520004   102.419998   142.869995   \n",
       "68 2024-01-19 00:00:00-05:00  4796.560059  3577.030029  4839.810059   \n",
       "18 1967-05-04 00:00:00-04:00    94.059998    73.199997    94.320000   \n",
       "\n",
       "    DrawdownPercent  RecoveryDuration  DrawdownDuration  FullCycleDuration  \n",
       "56        56.775388              1480               517               1997  \n",
       "54        49.146948              1694               928               2622  \n",
       "24        48.203593              2114               629               2743  \n",
       "22        36.061641               650               542               1193  \n",
       "65        33.924960               148                32                180  \n",
       "35        33.509515               599               101                701  \n",
       "15        27.973568               434               195                629  \n",
       "27        27.113582                83               621                705  \n",
       "68        25.425097               464               281                746  \n",
       "18        22.177335               209               239                448  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corrections_df = pd.DataFrame(corrections)\n",
    "corrections_df.sort_values(by='DrawdownPercent', ascending=False, inplace=True)\n",
    "\n",
    "corrections_df.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "45b3c3cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.25    21.5\n",
       "0.50    39.0\n",
       "0.75    89.0\n",
       "Name: DrawdownDuration, dtype: float64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "percentiles = corrections_df['DrawdownDuration'].quantile([0.25, 0.5, 0.75])\n",
    "percentiles\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "249f02bd",
   "metadata": {},
   "source": [
    "### Question 4.  [Stocks] Earnings Surprise Analysis for Amazon (AMZN)\n",
    "\n",
    "\n",
    "**Calculate the median 2-day percentage change in stock prices following positive earnings surprises days.**\n",
    "\n",
    "Steps:\n",
    "1. Load earnings data from CSV ([ha1_Amazon.csv](ha1_Amazon.csv)) containing earnings dates, EPS estimates, and actual EPS\n",
    "2. Download complete historical price data using yfinance\n",
    "3. Calculate 2-day percentage changes for all historical dates: for each sequence of 3 consecutive trading days (Day 1, Day 2, Day 3), compute the return as Close_Day3 / Close_Day1 - 1. (Assume Day 2 may correspond to the earnings announcement.)\n",
    "4. Identify positive earnings surprises (where \"actual EPS > estimated EPS\" OR \"Surprise (%)>0\")\n",
    "5. Calculate 2-day percentage changes following positive earnings surprises\n",
    "6. Compare the median 2-day percentage change for positive surprises vs. all historical dates\n",
    "\n",
    "Context: Earnings announcements, especially when they exceed analyst expectations, can significantly impact stock prices in the short term.\n",
    "\n",
    "Reference: Yahoo Finance earnings calendar - https://finance.yahoo.com/calendar/earnings?symbol=AMZN\n",
    "\n",
    "*Additional*: Is there a correlation between the magnitude of the earnings surprise and the stock price reaction? Does the market react differently to earnings surprises during bull vs. bear markets?)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c186098f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 86 positive surprise events\n",
      "\n",
      "Results:\n",
      "Number of positive-surprise events with valid returns: 86\n",
      "Total number of valid 2-day return periods: 7049\n",
      "Median 2-day return (all periods): 0.16%\n",
      "Median 2-day return (positive surprises): 1.04%\n",
      "Difference: 0.88 percentage points\n",
      "\n",
      "Sample positive surprise events:\n",
      "  Earnings Date       Date  2DayReturn_All\n",
      "0    1997-07-10 1997-07-10       -0.013457\n",
      "1    1997-10-27 1997-10-27       -0.015543\n",
      "2    1998-01-22 1998-01-22       -0.026695\n",
      "3    1998-04-27 1998-04-27        0.126658\n",
      "4    1998-07-22 1998-07-22       -0.033601\n",
      "\n",
      "Sample earnings data processing:\n",
      "  Earnings Date  Reported EPS  EPS Estimate  Surprise (%)  PositiveSurprise\n",
      "0    2026-04-29           NaN           NaN           NaN             False\n",
      "1    2026-02-04           NaN           NaN           NaN             False\n",
      "2    2025-10-29           NaN           NaN           NaN             False\n",
      "3    2025-07-30           NaN           NaN           NaN             False\n",
      "4    2025-05-01           NaN           NaN         16.74              True\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "\n",
    "# 1. Load and clean earnings data\n",
    "amzn_earnings = pd.read_csv('ha1_Amazon.csv', sep=';')\n",
    "amzn_earnings.dropna(how='all', inplace=True)\n",
    "\n",
    "# Extract just the date part (drop \"at HH:MM AM/PM\")\n",
    "amzn_earnings['Earnings Date'] = (\n",
    "    amzn_earnings['Earnings Date']\n",
    "      .str.extract(r'(.*)\\s+at')[0]  # Fixed regex - added '+' for multiple spaces\n",
    "      .pipe(pd.to_datetime, errors='coerce')\n",
    ")\n",
    "\n",
    "# Convert numeric columns - handle percentage signs and other formatting\n",
    "for col in ['Surprise (%)', 'Reported EPS', 'EPS Estimate']:\n",
    "    if col == 'Surprise (%)':\n",
    "        # Remove % sign if present and convert\n",
    "        amzn_earnings[col] = (amzn_earnings[col]\n",
    "                             .astype(str)\n",
    "                             .str.replace('%', '')\n",
    "                             .pipe(pd.to_numeric, errors='coerce'))\n",
    "    else:\n",
    "        amzn_earnings[col] = pd.to_numeric(amzn_earnings[col], errors='coerce')\n",
    "\n",
    "# Flag positive surprises\n",
    "amzn_earnings['PositiveSurprise'] = (\n",
    "    (amzn_earnings['Reported EPS'] > amzn_earnings['EPS Estimate']) |\n",
    "    (amzn_earnings['Surprise (%)'] > 0)\n",
    ")\n",
    "\n",
    "# Keep only valid, past positive-surprise events\n",
    "positive_surprises = amzn_earnings.loc[\n",
    "    amzn_earnings['PositiveSurprise'] &\n",
    "    amzn_earnings['Earnings Date'].notna() &\n",
    "    (amzn_earnings['Earnings Date'] < pd.Timestamp.today().normalize()),\n",
    "    ['Earnings Date']\n",
    "].copy()\n",
    "\n",
    "print(f\"Found {len(positive_surprises)} positive surprise events\")\n",
    "\n",
    "# 2. Download historical daily prices\n",
    "ticker = yf.Ticker(\"AMZN\")\n",
    "amzn_price = ticker.history(start='1997-01-01', interval='1d').reset_index()\n",
    "\n",
    "# Drop timezone so merges work cleanly\n",
    "amzn_price['Date'] = amzn_price['Date'].dt.tz_localize(None)\n",
    "amzn_price.sort_values('Date', inplace=True, ignore_index=True)\n",
    "\n",
    "# 3. Calculate 2-day returns for ALL trading days\n",
    "# For each day i, calculate return from day i-1 to day i+1\n",
    "amzn_price['Close_Day1'] = amzn_price['Close'].shift(1)   # Previous day close\n",
    "amzn_price['Close_Day3'] = amzn_price['Close'].shift(-1)  # Next day close\n",
    "amzn_price['2DayReturn_All'] = amzn_price['Close_Day3'] / amzn_price['Close_Day1'] - 1\n",
    "\n",
    "# Remove rows with NaN returns\n",
    "valid_returns = amzn_price.dropna(subset=['2DayReturn_All'])\n",
    "\n",
    "# 4. For earnings events, find the corresponding trading day\n",
    "# Use merge_asof to find the first trading day on or after each earnings date\n",
    "earn_aligned = pd.merge_asof(\n",
    "    positive_surprises.sort_values('Earnings Date'),\n",
    "    amzn_price[['Date', 'Close_Day1', 'Close_Day3', '2DayReturn_All']],\n",
    "    left_on='Earnings Date',\n",
    "    right_on='Date',\n",
    "    direction='forward'\n",
    ")\n",
    "\n",
    "# Remove any rows where we couldn't find a matching trading day or calculate return\n",
    "earn_aligned = earn_aligned.dropna(subset=['2DayReturn_All'])\n",
    "\n",
    "# 5. Calculate medians\n",
    "median_surprise = earn_aligned['2DayReturn_All'].median()\n",
    "median_all = valid_returns['2DayReturn_All'].median()\n",
    "\n",
    "# 6. Output results\n",
    "print(f\"\\nResults:\")\n",
    "print(f\"Number of positive-surprise events with valid returns: {len(earn_aligned)}\")\n",
    "print(f\"Total number of valid 2-day return periods: {len(valid_returns)}\")\n",
    "print(f\"Median 2-day return (all periods): {median_all*100:.2f}%\")\n",
    "print(f\"Median 2-day return (positive surprises): {median_surprise*100:.2f}%\")\n",
    "print(f\"Difference: {(median_surprise - median_all)*100:.2f} percentage points\")\n",
    "\n",
    "# Debug: Show some sample data\n",
    "print(f\"\\nSample positive surprise events:\")\n",
    "print(earn_aligned[['Earnings Date', 'Date', '2DayReturn_All']].head())\n",
    "\n",
    "print(f\"\\nSample earnings data processing:\")\n",
    "print(amzn_earnings[['Earnings Date', 'Reported EPS', 'EPS Estimate', 'Surprise (%)', 'PositiveSurprise']].head())"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0e70b031",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "\n",
    "# 1. Load and clean earnings data\n",
    "amzn_earnings = pd.read_csv('ha1_Amazon.csv', sep=';')\n",
    "amzn_earnings.dropna(how='all', inplace=True)\n",
    "\n",
    "# Extract just the date part (drop \"at HH:MM AM/PM\")\n",
    "amzn_earnings['Earnings Date'] = (\n",
    "    amzn_earnings['Earnings Date']\n",
    "      .str.extract(r'(.*)\\s+at')[0]  # Fixed regex - added '+' for multiple spaces\n",
    "      .pipe(pd.to_datetime, errors='coerce')\n",
    ")\n",
    "\n",
    "# Convert numeric columns - handle percentage signs and other formatting\n",
    "for col in ['Surprise (%)', 'Reported EPS', 'EPS Estimate']:\n",
    "    if col == 'Surprise (%)':\n",
    "        # Remove % sign if present and convert\n",
    "        amzn_earnings[col] = (amzn_earnings[col]\n",
    "                             .astype(str)\n",
    "                             .str.replace('%', '')\n",
    "                             .pipe(pd.to_numeric, errors='coerce'))\n",
    "    else:\n",
    "        amzn_earnings[col] = pd.to_numeric(amzn_earnings[col], errors='coerce')\n",
    "\n",
    "# Flag positive surprises\n",
    "amzn_earnings['PositiveSurprise'] = (\n",
    "    (amzn_earnings['Reported EPS'] > amzn_earnings['EPS Estimate']) |\n",
    "    (amzn_earnings['Surprise (%)'] > 0)\n",
    ")\n",
    "\n",
    "# Keep only valid, past positive-surprise events\n",
    "positive_surprises = amzn_earnings.loc[\n",
    "    amzn_earnings['PositiveSurprise'] &\n",
    "    amzn_earnings['Earnings Date'].notna() &\n",
    "    (amzn_earnings['Earnings Date'] < pd.Timestamp.today().normalize()),\n",
    "    ['Earnings Date']\n",
    "].copy()\n",
    "\n",
    "print(f\"Found {len(positive_surprises)} positive surprise events\")\n",
    "\n",
    "# 2. Download historical daily prices\n",
    "ticker = yf.Ticker(\"AMZN\")\n",
    "amzn_price = ticker.history(start='1997-01-01', interval='1d').reset_index()\n",
    "\n",
    "# Drop timezone so merges work cleanly\n",
    "amzn_price['Date'] = amzn_price['Date'].dt.tz_localize(None)\n",
    "amzn_price.sort_values('Date', inplace=True, ignore_index=True)\n",
    "\n",
    "# 3. Calculate 2-day returns for ALL trading days\n",
    "# Method 1: From day i-1 to day i+1 (spans 2 trading days)\n",
    "amzn_price['Close_Day1'] = amzn_price['Close'].shift(1)   # Previous day close\n",
    "amzn_price['Close_Day3'] = amzn_price['Close'].shift(-1)  # Next day close\n",
    "amzn_price['2DayReturn_Method1'] = amzn_price['Close_Day3'] / amzn_price['Close_Day1'] - 1\n",
    "\n",
    "# Method 2: From day i to day i+2 (following 2 trading days after announcement)\n",
    "amzn_price['Close_Day2Plus'] = amzn_price['Close'].shift(-2)  # Two days ahead\n",
    "amzn_price['2DayReturn_Method2'] = amzn_price['Close_Day2Plus'] / amzn_price['Close'] - 1\n",
    "\n",
    "# Remove rows with NaN returns for both methods\n",
    "valid_returns_m1 = amzn_price.dropna(subset=['2DayReturn_Method1'])\n",
    "valid_returns_m2 = amzn_price.dropna(subset=['2DayReturn_Method2'])\n",
    "\n",
    "# 4. For earnings events, find the corresponding trading day\n",
    "# Use merge_asof to find the first trading day on or after each earnings date\n",
    "earn_aligned = pd.merge_asof(\n",
    "    positive_surprises.sort_values('Earnings Date'),\n",
    "    amzn_price[['Date', 'Close', 'Close_Day1', 'Close_Day3', 'Close_Day2Plus', '2DayReturn_Method1', '2DayReturn_Method2']],\n",
    "    left_on='Earnings Date',\n",
    "    right_on='Date',\n",
    "    direction='forward'\n",
    ")\n",
    "\n",
    "# Remove any rows where we couldn't find a matching trading day or calculate return\n",
    "earn_aligned_m1 = earn_aligned.dropna(subset=['2DayReturn_Method1'])\n",
    "earn_aligned_m2 = earn_aligned.dropna(subset=['2DayReturn_Method2'])\n",
    "\n",
    "# 5. Calculate medians for both methods\n",
    "# Method 1: Day i-1 to Day i+1\n",
    "median_surprise_m1 = earn_aligned_m1['2DayReturn_Method1'].median()\n",
    "median_all_m1 = valid_returns_m1['2DayReturn_Method1'].median()\n",
    "\n",
    "# Method 2: Day i to Day i+2 (following 2 days after announcement)\n",
    "median_surprise_m2 = earn_aligned_m2['2DayReturn_Method2'].median()\n",
    "median_all_m2 = valid_returns_m2['2DayReturn_Method2'].median()\n",
    "\n",
    "# 6. Output results for both methods\n",
    "print(f\"\\nMethod 1 Results (Day i-1 to Day i+1):\")\n",
    "print(f\"Number of positive-surprise events with valid returns: {len(earn_aligned_m1)}\")\n",
    "print(f\"Total number of valid 2-day return periods: {len(valid_returns_m1)}\")\n",
    "print(f\"Median 2-day return (all periods): {median_all_m1*100:.4f}%\")\n",
    "print(f\"Median 2-day return (positive surprises): {median_surprise_m1*100:.4f}%\")\n",
    "\n",
    "print(f\"\\nMethod 2 Results (Day i to Day i+2 - Following 2 days):\")\n",
    "print(f\"Number of positive-surprise events with valid returns: {len(earn_aligned_m2)}\")\n",
    "print(f\"Total number of valid 2-day return periods: {len(valid_returns_m2)}\")\n",
    "print(f\"Median 2-day return (all periods): {median_all_m2*100:.4f}%\")\n",
    "print(f\"Median 2-day return (positive surprises): {median_surprise_m2*100:.4f}%\")\n",
    "\n",
    "# Debug: Show some sample data\n",
    "print(f\"\\nSample positive surprise events (Method 2):\")\n",
    "print(earn_aligned_m2[['Earnings Date', 'Date', '2DayReturn_Method2']].head(10))\n",
    "\n",
    "print(f\"\\nSample earnings data processing:\")\n",
    "print(amzn_earnings[['Earnings Date', 'Reported EPS', 'EPS Estimate', 'Surprise (%)', 'PositiveSurprise']].head())"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b1a267ab",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "\n",
    "# 1. Load and clean earnings data\n",
    "amzn_earnings = pd.read_csv('ha1_Amazon.csv', sep=';')\n",
    "amzn_earnings.dropna(how='all', inplace=True)\n",
    "\n",
    "# Extract just the date part (drop \"at HH:MM AM/PM\")\n",
    "amzn_earnings['Earnings Date'] = (\n",
    "    amzn_earnings['Earnings Date']\n",
    "      .str.extract(r'(.*)\\s+at')[0]  # Fixed regex - added '+' for multiple spaces\n",
    "      .pipe(pd.to_datetime, errors='coerce')\n",
    ")\n",
    "\n",
    "# Convert numeric columns - handle percentage signs and other formatting\n",
    "for col in ['Surprise (%)', 'Reported EPS', 'EPS Estimate']:\n",
    "    if col == 'Surprise (%)':\n",
    "        # Remove % sign if present and convert\n",
    "        amzn_earnings[col] = (amzn_earnings[col]\n",
    "                             .astype(str)\n",
    "                             .str.replace('%', '')\n",
    "                             .pipe(pd.to_numeric, errors='coerce'))\n",
    "    else:\n",
    "        amzn_earnings[col] = pd.to_numeric(amzn_earnings[col], errors='coerce')\n",
    "\n",
    "# Flag positive surprises\n",
    "amzn_earnings['PositiveSurprise'] = (\n",
    "    (amzn_earnings['Reported EPS'] > amzn_earnings['EPS Estimate']) |\n",
    "    (amzn_earnings['Surprise (%)'] > 0)\n",
    ")\n",
    "\n",
    "# Keep only valid, past positive-surprise events\n",
    "positive_surprises = amzn_earnings.loc[\n",
    "    amzn_earnings['PositiveSurprise'] &\n",
    "    amzn_earnings['Earnings Date'].notna() &\n",
    "    (amzn_earnings['Earnings Date'] < pd.Timestamp.today().normalize()),\n",
    "    ['Earnings Date']\n",
    "].copy()\n",
    "\n",
    "print(f\"Found {len(positive_surprises)} positive surprise events\")\n",
    "\n",
    "# 2. Download historical daily prices\n",
    "ticker = yf.Ticker(\"AMZN\")\n",
    "amzn_price = ticker.history(start='1997-01-01', interval='1d').reset_index()\n",
    "\n",
    "# Drop timezone so merges work cleanly\n",
    "amzn_price['Date'] = amzn_price['Date'].dt.tz_localize(None)\n",
    "amzn_price.sort_values('Date', inplace=True, ignore_index=True)\n",
    "\n",
    "# 3. Calculate 2-day returns for ALL trading days\n",
    "# Method 1: From day i-1 to day i+1 (spans 2 trading days)\n",
    "amzn_price['Close_Day1'] = amzn_price['Close'].shift(1)   # Previous day close\n",
    "amzn_price['Close_Day3'] = amzn_price['Close'].shift(-1)  # Next day close\n",
    "amzn_price['2DayReturn_Method1'] = amzn_price['Close_Day3'] / amzn_price['Close_Day1'] - 1\n",
    "\n",
    "# Method 2: From day i to day i+2 (following 2 trading days after announcement)\n",
    "amzn_price['Close_Day2Plus'] = amzn_price['Close'].shift(-2)  # Two days ahead\n",
    "amzn_price['2DayReturn_Method2'] = amzn_price['Close_Day2Plus'] / amzn_price['Close'] - 1\n",
    "\n",
    "# Remove rows with NaN returns for both methods\n",
    "valid_returns_m1 = amzn_price.dropna(subset=['2DayReturn_Method1'])\n",
    "valid_returns_m2 = amzn_price.dropna(subset=['2DayReturn_Method2'])\n",
    "\n",
    "# 4. For earnings events, find the corresponding trading day\n",
    "# Use merge_asof to find the first trading day on or after each earnings date\n",
    "earn_aligned = pd.merge_asof(\n",
    "    positive_surprises.sort_values('Earnings Date'),\n",
    "    amzn_price[['Date', 'Close', 'Close_Day1', 'Close_Day3', 'Close_Day2Plus', '2DayReturn_Method1', '2DayReturn_Method2']],\n",
    "    left_on='Earnings Date',\n",
    "    right_on='Date',\n",
    "    direction='forward'\n",
    ")\n",
    "\n",
    "# Remove any rows where we couldn't find a matching trading day or calculate return\n",
    "earn_aligned_m1 = earn_aligned.dropna(subset=['2DayReturn_Method1'])\n",
    "earn_aligned_m2 = earn_aligned.dropna(subset=['2DayReturn_Method2'])\n",
    "\n",
    "# 5. Calculate medians for both methods\n",
    "# Method 1: Day i-1 to Day i+1\n",
    "median_surprise_m1 = earn_aligned_m1['2DayReturn_Method1'].median()\n",
    "median_all_m1 = valid_returns_m1['2DayReturn_Method1'].median()\n",
    "\n",
    "# Method 2: Day i to Day i+2 (following 2 days after announcement)\n",
    "median_surprise_m2 = earn_aligned_m2['2DayReturn_Method2'].median()\n",
    "median_all_m2 = valid_returns_m2['2DayReturn_Method2'].median()\n",
    "\n",
    "# 6. Output results for both methods\n",
    "print(f\"\\nMethod 1 Results (Day i-1 to Day i+1):\")\n",
    "print(f\"Number of positive-surprise events with valid returns: {len(earn_aligned_m1)}\")\n",
    "print(f\"Total number of valid 2-day return periods: {len(valid_returns_m1)}\")\n",
    "print(f\"Median 2-day return (all periods): {median_all_m1*100:.4f}%\")\n",
    "print(f\"Median 2-day return (positive surprises): {median_surprise_m1*100:.4f}%\")\n",
    "\n",
    "print(f\"\\nMethod 2 Results (Day i to Day i+2 - Following 2 days):\")\n",
    "print(f\"Number of positive-surprise events with valid returns: {len(earn_aligned_m2)}\")\n",
    "print(f\"Total number of valid 2-day return periods: {len(valid_returns_m2)}\")\n",
    "print(f\"Median 2-day return (all periods): {median_all_m2*100:.4f}%\")\n",
    "print(f\"Median 2-day return (positive surprises): {median_surprise_m2*100:.4f}%\")\n",
    "\n",
    "# Additional debugging and alternative calculations\n",
    "print(f\"\\nDebugging Information:\")\n",
    "\n",
    "# Check if there are any extreme outliers\n",
    "print(f\"Method 1 - Min: {earn_aligned_m1['2DayReturn_Method1'].min()*100:.2f}%, Max: {earn_aligned_m1['2DayReturn_Method1'].max()*100:.2f}%\")\n",
    "print(f\"Method 2 - Min: {earn_aligned_m2['2DayReturn_Method2'].min()*100:.2f}%, Max: {earn_aligned_m2['2DayReturn_Method2'].max()*100:.2f}%\")\n",
    "\n",
    "# Try calculating mean instead of median\n",
    "mean_surprise_m1 = earn_aligned_m1['2DayReturn_Method1'].mean()\n",
    "mean_surprise_m2 = earn_aligned_m2['2DayReturn_Method2'].mean()\n",
    "print(f\"Method 1 - Mean: {mean_surprise_m1*100:.4f}%\")\n",
    "print(f\"Method 2 - Mean: {mean_surprise_m2*100:.4f}%\")\n",
    "\n",
    "# Check quartiles\n",
    "q25_m1, q75_m1 = earn_aligned_m1['2DayReturn_Method1'].quantile([0.25, 0.75])\n",
    "q25_m2, q75_m2 = earn_aligned_m2['2DayReturn_Method2'].quantile([0.25, 0.75])\n",
    "print(f\"Method 1 - Q1: {q25_m1*100:.2f}%, Q3: {q75_m1*100:.2f}%\")\n",
    "print(f\"Method 2 - Q1: {q25_m2*100:.2f}%, Q3: {q75_m2*100:.2f}%\")\n",
    "\n",
    "# Try different time window - maybe it's asking for 1-day return after earnings\n",
    "amzn_price['1DayReturn_After'] = amzn_price['Close'].shift(-1) / amzn_price['Close'] - 1\n",
    "earn_aligned_1day = pd.merge_asof(\n",
    "    positive_surprises.sort_values('Earnings Date'),\n",
    "    amzn_price[['Date', '1DayReturn_After']],\n",
    "    left_on='Earnings Date',\n",
    "    right_on='Date',\n",
    "    direction='forward'\n",
    ").dropna(subset=['1DayReturn_After'])\n",
    "\n",
    "median_1day = earn_aligned_1day['1DayReturn_After'].median()\n",
    "print(f\"\\n1-day return after earnings median: {median_1day*100:.4f}%\")\n",
    "\n",
    "# Check if percentage values need to be divided by 100\n",
    "print(f\"\\nIf we divide by 100 (in case percentages were already in percent form):\")\n",
    "print(f\"Method 1 median / 100: {median_surprise_m1:.4f}%\")\n",
    "print(f\"Method 2 median / 100: {median_surprise_m2:.4f}%\")\n",
    "\n",
    "# Show sample data\n",
    "print(f\"\\nSample earnings events with returns:\")\n",
    "sample_data = earn_aligned_m1[['Earnings Date', 'Date', '2DayReturn_Method1', 'Close', 'Close_Day1', 'Close_Day3']].head(10)\n",
    "for col in ['2DayReturn_Method1']:\n",
    "    sample_data[f'{col}_pct'] = sample_data[col] * 100\n",
    "print(sample_data[['Earnings Date', 'Date', '2DayReturn_Method1_pct', 'Close', 'Close_Day1', 'Close_Day3']])\n",
    "\n",
    "# Check earnings data more carefully\n",
    "print(f\"\\nEarnings data analysis:\")\n",
    "print(f\"Total earnings records: {len(amzn_earnings)}\")\n",
    "print(f\"Records with valid dates: {amzn_earnings['Earnings Date'].notna().sum()}\")\n",
    "print(f\"Records with Surprise % > 0: {(amzn_earnings['Surprise (%)'] > 0).sum()}\")\n",
    "print(f\"Records with Actual > Estimate: {(amzn_earnings['Reported EPS'] > amzn_earnings['EPS Estimate']).sum()}\")\n",
    "print(f\"Total positive surprises: {amzn_earnings['PositiveSurprise'].sum()}\")\n",
    "\n",
    "# Show some sample earnings data\n",
    "print(f\"\\nSample earnings data:\")\n",
    "sample_earnings = amzn_earnings[['Earnings Date', 'Reported EPS', 'EPS Estimate', 'Surprise (%)', 'PositiveSurprise']].head(10)\n",
    "print(sample_earnings)\n",
    "\n",
    "# Check if we should use different surprise criteria\n",
    "print(f\"\\nAlternative surprise definitions:\")\n",
    "alt_positive1 = (amzn_earnings['Surprise (%)'] > 0) & amzn_earnings['Surprise (%)'].notna()\n",
    "alt_positive2 = (amzn_earnings['Reported EPS'] > amzn_earnings['EPS Estimate']) & amzn_earnings['Reported EPS'].notna() & amzn_earnings['EPS Estimate'].notna()\n",
    "\n",
    "print(f\"Only Surprise % > 0: {alt_positive1.sum()} events\")\n",
    "print(f\"Only Actual > Estimate: {alt_positive2.sum()} events\")\n",
    "\n",
    "# Try with just Surprise % > 0\n",
    "if alt_positive1.sum() > 0:\n",
    "    alt_surprises = amzn_earnings.loc[\n",
    "        alt_positive1 & \n",
    "        amzn_earnings['Earnings Date'].notna() &\n",
    "        (amzn_earnings['Earnings Date'] < pd.Timestamp.today().normalize()),\n",
    "        ['Earnings Date']\n",
    "    ].copy()\n",
    "    \n",
    "    alt_earn_aligned = pd.merge_asof(\n",
    "        alt_surprises.sort_values('Earnings Date'),\n",
    "        amzn_price[['Date', '2DayReturn_Method1']],\n",
    "        left_on='Earnings Date',\n",
    "        right_on='Date',\n",
    "        direction='forward'\n",
    "    ).dropna(subset=['2DayReturn_Method1'])\n",
    "    \n",
    "    alt_median = alt_earn_aligned['2DayReturn_Method1'].median()\n",
    "    print(f\"Alternative median (Surprise % > 0 only): {alt_median*100:.4f}% ({len(alt_earn_aligned)} events)\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7f283e54",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "\n",
    "# 1. Load and clean earnings data\n",
    "amzn_earnings = pd.read_csv('ha1_Amazon.csv', sep=';')\n",
    "amzn_earnings.dropna(how='all', inplace=True)\n",
    "\n",
    "# Extract just the date part (drop \"at HH:MM AM/PM\")\n",
    "amzn_earnings['Earnings Date'] = (\n",
    "    amzn_earnings['Earnings Date']\n",
    "      .str.extract(r'(.*)\\s+at')[0]  # Fixed regex - added '+' for multiple spaces\n",
    "      .pipe(pd.to_datetime, errors='coerce')\n",
    ")\n",
    "\n",
    "# Convert numeric columns - handle percentage signs and other formatting\n",
    "for col in ['Surprise (%)', 'Reported EPS', 'EPS Estimate']:\n",
    "    if col == 'Surprise (%)':\n",
    "        # Remove % sign if present and convert\n",
    "        amzn_earnings[col] = (amzn_earnings[col]\n",
    "                             .astype(str)\n",
    "                             .str.replace('%', '')\n",
    "                             .pipe(pd.to_numeric, errors='coerce'))\n",
    "    else:\n",
    "        amzn_earnings[col] = pd.to_numeric(amzn_earnings[col], errors='coerce')\n",
    "\n",
    "# Flag positive surprises\n",
    "amzn_earnings['PositiveSurprise'] = (\n",
    "    (amzn_earnings['Reported EPS'] > amzn_earnings['EPS Estimate']) |\n",
    "    (amzn_earnings['Surprise (%)'] > 0)\n",
    ")\n",
    "\n",
    "# Keep only valid, past positive-surprise events\n",
    "positive_surprises = amzn_earnings.loc[\n",
    "    amzn_earnings['PositiveSurprise'] &\n",
    "    amzn_earnings['Earnings Date'].notna() &\n",
    "    (amzn_earnings['Earnings Date'] < pd.Timestamp.today().normalize()),\n",
    "    ['Earnings Date']\n",
    "].copy()\n",
    "\n",
    "print(f\"Found {len(positive_surprises)} positive surprise events\")\n",
    "\n",
    "# 2. Download historical daily prices\n",
    "ticker = yf.Ticker(\"AMZN\")\n",
    "amzn_price = ticker.history(start='1997-01-01', interval='1d').reset_index()\n",
    "\n",
    "# Drop timezone so merges work cleanly\n",
    "amzn_price['Date'] = amzn_price['Date'].dt.tz_localize(None)\n",
    "amzn_price.sort_values('Date', inplace=True, ignore_index=True)\n",
    "\n",
    "# 3. Calculate 2-day returns for ALL trading days\n",
    "# Method 1: From day i-1 to day i+1 (spans 2 trading days)\n",
    "amzn_price['Close_Day1'] = amzn_price['Close'].shift(1)   # Previous day close\n",
    "amzn_price['Close_Day3'] = amzn_price['Close'].shift(-1)  # Next day close\n",
    "amzn_price['2DayReturn_Method1'] = amzn_price['Close_Day3'] / amzn_price['Close_Day1'] - 1\n",
    "\n",
    "# Method 2: From day i to day i+2 (following 2 trading days after announcement)\n",
    "amzn_price['Close_Day2Plus'] = amzn_price['Close'].shift(-2)  # Two days ahead\n",
    "amzn_price['2DayReturn_Method2'] = amzn_price['Close_Day2Plus'] / amzn_price['Close'] - 1\n",
    "\n",
    "# Remove rows with NaN returns for both methods\n",
    "valid_returns_m1 = amzn_price.dropna(subset=['2DayReturn_Method1'])\n",
    "valid_returns_m2 = amzn_price.dropna(subset=['2DayReturn_Method2'])\n",
    "\n",
    "# 4. For earnings events, find the corresponding trading day\n",
    "# Use merge_asof to find the first trading day on or after each earnings date\n",
    "earn_aligned = pd.merge_asof(\n",
    "    positive_surprises.sort_values('Earnings Date'),\n",
    "    amzn_price[['Date', 'Close', 'Close_Day1', 'Close_Day3', 'Close_Day2Plus', '2DayReturn_Method1', '2DayReturn_Method2']],\n",
    "    left_on='Earnings Date',\n",
    "    right_on='Date',\n",
    "    direction='forward'\n",
    ")\n",
    "\n",
    "# Remove any rows where we couldn't find a matching trading day or calculate return\n",
    "earn_aligned_m1 = earn_aligned.dropna(subset=['2DayReturn_Method1'])\n",
    "earn_aligned_m2 = earn_aligned.dropna(subset=['2DayReturn_Method2'])\n",
    "\n",
    "# 5. Calculate medians for both methods\n",
    "# Method 1: Day i-1 to Day i+1\n",
    "median_surprise_m1 = earn_aligned_m1['2DayReturn_Method1'].median()\n",
    "median_all_m1 = valid_returns_m1['2DayReturn_Method1'].median()\n",
    "\n",
    "# Method 2: Day i to Day i+2 (following 2 days after announcement)\n",
    "median_surprise_m2 = earn_aligned_m2['2DayReturn_Method2'].median()\n",
    "median_all_m2 = valid_returns_m2['2DayReturn_Method2'].median()\n",
    "\n",
    "# 6. Output results for both methods\n",
    "print(f\"\\nMethod 1 Results (Day i-1 to Day i+1):\")\n",
    "print(f\"Number of positive-surprise events with valid returns: {len(earn_aligned_m1)}\")\n",
    "print(f\"Total number of valid 2-day return periods: {len(valid_returns_m1)}\")\n",
    "print(f\"Median 2-day return (all periods): {median_all_m1*100:.4f}%\")\n",
    "print(f\"Median 2-day return (positive surprises): {median_surprise_m1*100:.4f}%\")\n",
    "\n",
    "print(f\"\\nMethod 2 Results (Day i to Day i+2 - Following 2 days):\")\n",
    "print(f\"Number of positive-surprise events with valid returns: {len(earn_aligned_m2)}\")\n",
    "print(f\"Total number of valid 2-day return periods: {len(valid_returns_m2)}\")\n",
    "print(f\"Median 2-day return (all periods): {median_all_m2*100:.4f}%\")\n",
    "print(f\"Median 2-day return (positive surprises): {median_surprise_m2*100:.4f}%\")\n",
    "\n",
    "# Additional debugging and alternative calculations\n",
    "print(f\"\\nDebugging Information:\")\n",
    "\n",
    "# Check if there are any extreme outliers\n",
    "print(f\"Method 1 - Min: {earn_aligned_m1['2DayReturn_Method1'].min()*100:.2f}%, Max: {earn_aligned_m1['2DayReturn_Method1'].max()*100:.2f}%\")\n",
    "print(f\"Method 2 - Min: {earn_aligned_m2['2DayReturn_Method2'].min()*100:.2f}%, Max: {earn_aligned_m2['2DayReturn_Method2'].max()*100:.2f}%\")\n",
    "\n",
    "# Try calculating mean instead of median\n",
    "mean_surprise_m1 = earn_aligned_m1['2DayReturn_Method1'].mean()\n",
    "mean_surprise_m2 = earn_aligned_m2['2DayReturn_Method2'].mean()\n",
    "print(f\"Method 1 - Mean: {mean_surprise_m1*100:.4f}%\")\n",
    "print(f\"Method 2 - Mean: {mean_surprise_m2*100:.4f}%\")\n",
    "\n",
    "# Check quartiles\n",
    "q25_m1, q75_m1 = earn_aligned_m1['2DayReturn_Method1'].quantile([0.25, 0.75])\n",
    "q25_m2, q75_m2 = earn_aligned_m2['2DayReturn_Method2'].quantile([0.25, 0.75])\n",
    "print(f\"Method 1 - Q1: {q25_m1*100:.2f}%, Q3: {q75_m1*100:.2f}%\")\n",
    "print(f\"Method 2 - Q1: {q25_m2*100:.2f}%, Q3: {q75_m2*100:.2f}%\")\n",
    "\n",
    "# Try different time window - maybe it's asking for 1-day return after earnings\n",
    "amzn_price['1DayReturn_After'] = amzn_price['Close'].shift(-1) / amzn_price['Close'] - 1\n",
    "earn_aligned_1day = pd.merge_asof(\n",
    "    positive_surprises.sort_values('Earnings Date'),\n",
    "    amzn_price[['Date', '1DayReturn_After']],\n",
    "    left_on='Earnings Date',\n",
    "    right_on='Date',\n",
    "    direction='forward'\n",
    ").dropna(subset=['1DayReturn_After'])\n",
    "\n",
    "median_1day = earn_aligned_1day['1DayReturn_After'].median()\n",
    "print(f\"\\n1-day return after earnings median: {median_1day*100:.4f}%\")\n",
    "\n",
    "# Check if percentage values need to be divided by 100\n",
    "print(f\"\\nIf we divide by 100 (in case percentages were already in percent form):\")\n",
    "print(f\"Method 1 median / 100: {median_surprise_m1:.4f}%\")\n",
    "print(f\"Method 2 median / 100: {median_surprise_m2:.4f}%\")\n",
    "\n",
    "# Show sample data\n",
    "print(f\"\\nSample earnings events with returns:\")\n",
    "sample_data = earn_aligned_m1[['Earnings Date', 'Date', '2DayReturn_Method1', 'Close', 'Close_Day1', 'Close_Day3']].head(10)\n",
    "for col in ['2DayReturn_Method1']:\n",
    "    sample_data[f'{col}_pct'] = sample_data[col] * 100\n",
    "print(sample_data[['Earnings Date', 'Date', '2DayReturn_Method1_pct', 'Close', 'Close_Day1', 'Close_Day3']])\n",
    "\n",
    "# Check earnings data more carefully\n",
    "print(f\"\\nEarnings data analysis:\")\n",
    "print(f\"Total earnings records: {len(amzn_earnings)}\")\n",
    "print(f\"Records with valid dates: {amzn_earnings['Earnings Date'].notna().sum()}\")\n",
    "print(f\"Records with Surprise % > 0: {(amzn_earnings['Surprise (%)'] > 0).sum()}\")\n",
    "print(f\"Records with Actual > Estimate: {(amzn_earnings['Reported EPS'] > amzn_earnings['EPS Estimate']).sum()}\")\n",
    "print(f\"Total positive surprises: {amzn_earnings['PositiveSurprise'].sum()}\")\n",
    "\n",
    "# Show some sample earnings data\n",
    "print(f\"\\nSample earnings data:\")\n",
    "sample_earnings = amzn_earnings[['Earnings Date', 'Reported EPS', 'EPS Estimate', 'Surprise (%)', 'PositiveSurprise']].head(10)\n",
    "print(sample_earnings)\n",
    "\n",
    "# Check if we should use different surprise criteria\n",
    "print(f\"\\nAlternative surprise definitions:\")\n",
    "alt_positive1 = (amzn_earnings['Surprise (%)'] > 0) & amzn_earnings['Surprise (%)'].notna()\n",
    "alt_positive2 = (amzn_earnings['Reported EPS'] > amzn_earnings['EPS Estimate']) & amzn_earnings['Reported EPS'].notna() & amzn_earnings['EPS Estimate'].notna()\n",
    "\n",
    "print(f\"Only Surprise % > 0: {alt_positive1.sum()} events\")\n",
    "print(f\"Only Actual > Estimate: {alt_positive2.sum()} events\")\n",
    "\n",
    "# Try with just Surprise % > 0\n",
    "if alt_positive1.sum() > 0:\n",
    "    alt_surprises = amzn_earnings.loc[\n",
    "        alt_positive1 & \n",
    "        amzn_earnings['Earnings Date'].notna() &\n",
    "        (amzn_earnings['Earnings Date'] < pd.Timestamp.today().normalize()),\n",
    "        ['Earnings Date']\n",
    "    ].copy()\n",
    "    \n",
    "    alt_earn_aligned = pd.merge_asof(\n",
    "        alt_surprises.sort_values('Earnings Date'),\n",
    "        amzn_price[['Date', '2DayReturn_Method1']],\n",
    "        left_on='Earnings Date',\n",
    "        right_on='Date',\n",
    "        direction='forward'\n",
    "    ).dropna(subset=['2DayReturn_Method1'])\n",
    "    \n",
    "    alt_median = alt_earn_aligned['2DayReturn_Method1'].median()\n",
    "    print(f\"Alternative median (Surprise % > 0 only): {alt_median*100:.4f}% ({len(alt_earn_aligned)} events)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bc9dc88",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "141f66f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cd02e9b4",
   "metadata": {},
   "source": [
    "I want to build a personal investment assistant that recommends U.S. stocks to retail investors based on a combination of fundamental strength, price momentum, and recent investor sentiment. The assistant will use machine learning to predict the likelihood that a given stock will outperform its sector over the next 30 trading days — a horizon relevant to active retail traders."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
